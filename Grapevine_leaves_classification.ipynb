{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459bceb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Convolution2D, AveragePooling2D, GlobalAveragePooling2D \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import InceptionV3, VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from numpy import expand_dims\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isdir, isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_augimages(paths, datagen):\n",
    "### visualize augmented images generated using a Keras ImageDataGenerator ###\n",
    "    plt.figure(figsize = (14,28))\n",
    "    plt.suptitle('Augmented Images')\n",
    "    \n",
    "    midx = 0 # matplotlib index\n",
    "    for path in paths:\n",
    "        data = Image.open(path)\n",
    "        data = data.resize((224,224))\n",
    "        ''' add an extra dimension to the data array. \n",
    "        This step is often required to make the image compatible with the batch processing \n",
    "        expected by many deep learning models. The expand_dims function adds an additional \n",
    "        dimension at the beginning, effectively creating a batch of size 1 containing \n",
    "        the resized image.'''\n",
    "        samples = expand_dims(data, 0) \n",
    "        '''This line sets up an iterator (it) using a Keras ImageDataGenerator (datagen). \n",
    "        The iterator is configured to generate batches of data from the samples array, \n",
    "        with each batch containing one image (batch_size=1). \n",
    "        This iterator can be used to generate augmented versions of the image during training.'''\n",
    "        it = datagen.flow(samples, batch_size=1)\n",
    "    \n",
    "        # Show Original Image\n",
    "        plt.subplot(10,5, midx+1)\n",
    "        plt.imshow(data)\n",
    "        plt.axis('off')\n",
    "    \n",
    "        # Show Augmented Images\n",
    "        for idx, i in enumerate(range(4)):\n",
    "            midx += 1\n",
    "            plt.subplot(10,5, midx+1)\n",
    "            \n",
    "            batch = it.next()\n",
    "            image = batch[0].astype('uint8') # extracts the image data from the batch\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "        midx += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88985f0",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf441987",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = r'D:\\Praca\\Data_Science\\SDA_Kurs\\Grapevine_leaves\\Data\\Train_val\\\\'\n",
    "path_Ak = main_path + 'Ak'\n",
    "path_Ala_Idris = main_path + 'Ala_Idris'\n",
    "path_Buzgulu = main_path + 'Buzgulu'\n",
    "path_Dimnit = main_path + 'Dimnit'\n",
    "path_Nazli = main_path + 'Nazli'\n",
    "test_data_dir = r'D:\\Praca\\Data_Science\\SDA_Kurs\\Grapevine_leaves\\Data\\Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d39163",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_Ak = main_path + 'Ak'\n",
    "path_Ala_Idris = main_path + 'Ala_Idris'\n",
    "path_Buzgulu = main_path + 'Buzgulu'\n",
    "path_Dimnit = main_path + 'Dimnit'\n",
    "path_Nazli = main_path + 'Nazli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bdc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['image'] = os.listdir(path_Ak) + os.listdir(path_Ala_Idris) + os.listdir(path_Buzgulu) + os.listdir(path_Dimnit) + os.listdir(path_Nazli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3e6b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "paths = []\n",
    "for image in main_df['image']:\n",
    "    class_ = image.split(' (')[0]\n",
    "    classes.append(class_)\n",
    "    paths.append(main_path+class_+'\\\\'+image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['class'] = classes\n",
    "main_df['path'] = paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dc320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88d30a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample image from each class\n",
    "plt.figure(figsize = (15,12))\n",
    "for idx, i in enumerate(main_df['class'].unique()):\n",
    "    plt.subplot(4,7,idx+1)\n",
    "    df = main_df[main_df['class'] == i].reset_index(drop = True)\n",
    "    image_path = df.loc[rnd.randint(0, len(df))-1,'path']\n",
    "    img = Image.open(image_path)\n",
    "    img = img.resize((224,224))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(i)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c21b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add images' widths and heights to main_df\n",
    "widths, heights = [], []\n",
    "\n",
    "for path in tqdm(main_df[\"path\"]):\n",
    "    width, height = Image.open(path).size\n",
    "    widths.append(width)\n",
    "    heights.append(height)\n",
    "    \n",
    "main_df[\"width\"] = widths\n",
    "main_df[\"height\"] = heights\n",
    "main_df[\"dimension\"] = main_df[\"width\"] * main_df[\"height\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf583dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_df['width'].unique())\n",
    "print(main_df['height'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd7e3a4",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df549fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(main_df[['path', 'class']], \n",
    "                                                  main_df[['class']], \n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed11e2b",
   "metadata": {},
   "source": [
    "# Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c90edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.10,\n",
    "    brightness_range=[0.6,1.4],\n",
    "    channel_shift_range=0.7,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=preprocess_input\n",
    ") \n",
    "\n",
    "train_generator_resnet50 = resnet50_datagen.flow_from_dataframe(\n",
    "        X_train,  # This is the source directory for training images\n",
    "        x_col='path',\n",
    "        y_col='class',\n",
    "        target_size=(227, 227),  # All images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    ")\n",
    "val_generator_resnet50 = resnet50_datagen.flow_from_dataframe(\n",
    "        X_val,  # This is the source directory for training images\n",
    "        x_col='path',\n",
    "        y_col='class',\n",
    "        target_size=(227, 227),  # All images will be resized to 150x150\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_augimages(np.random.choice(main_df['path'],10), resnet50_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7027abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude the top (output) layer of the model\n",
    "# initialize the model's weights with pre-trained weights from the ImageNet dataset\n",
    "resnet50 = ResNet50(include_top = False, input_shape = (227,227,3), weights = 'imagenet')\n",
    "\n",
    "# training of all the convolution is set to false\n",
    "for layer in resnet50.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(resnet50.output)\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# the output tensor of the pre-trained ResNet-50 model\n",
    "model_resnet50 = Model(inputs = resnet50.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c9401",
   "metadata": {},
   "source": [
    "## Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d056bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ca72c",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74571f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_resnet50 = model_resnet50.fit(\n",
    "      train_generator_resnet50,\n",
    "      validation_data=val_generator_resnet50,\n",
    "      epochs=20,\n",
    "      verbose=2) #verbose=2 means that training progress will be displayed for each epoch, including metrics like loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424c164",
   "metadata": {},
   "source": [
    "# Previous approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = datagen.flow_from_directory(\n",
    "    train_data_dir, \n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=CLASSES,\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_gen = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes = CLASSES,\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_gen = datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615a837",
   "metadata": {},
   "source": [
    "## Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab289960",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3 = InceptionV3(include_top= False , weights= None , input_shape = (img_width , img_height , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6b7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3.load_weights('inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366fb334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freezing the layers so that they are not affected by the training on the new dataset\n",
    "for layer in inception_v3.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2acc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = inception_v3.get_layer('mixed7') #I will put my output nodes on this layer\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b6998",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "x = tf.keras.layers.Dense(100 , activation = 'relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(5 , activation = 'softmax')(x)\n",
    "pre_trained_model = tf.keras.models.Model(inputs = inception_v3.input , outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34836f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.compile(loss = tf.keras.losses.categorical_crossentropy , optimizer = tf.keras.optimizers.Adam() , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_pre_trained = pre_trained_model.fit(train_gen , epochs = EPOCHS , validation_data= validation_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21fa21",
   "metadata": {},
   "source": [
    "## BASIC SEQUENTIAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdfcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Add a 2D convolutional layer with 32 filters of size 3x3 and ReLU activation function\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "\n",
    "# Add a MaxPooling layer to reduce the data size\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add another 2D convolutional layer with 64 filters of size 3x3 and ReLU activation\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another MaxPooling layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add a 2D convolutional layer with 128 filters of size 3x3 and ReLU activation\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Add another MaxPooling layer\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the data into a one-dimensional array\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 512 units and ReLU activation\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add an output layer with one neuron and a sigmoid activation function (binary classification)\n",
    "model.add(Dense(len(CLASSES), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.0001), \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=len(validation_gen)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc163f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('basic_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e77ab",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3064ae63",
   "metadata": {},
   "source": [
    "### WITH DROPOUTS, BATCH_NORM AND EARLY STOPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(CLASSES), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323ac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "opt = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=opt, \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
    "STEP_SIZE_VALID=validation_gen.n//validation_gen.batch_size\n",
    "\n",
    "history = model.fit_generator(generator=train_gen,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=validation_gen,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[callback],\n",
    "                    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4109763",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(CLASSES), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.0001), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aede5d",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0319b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=len(validation_gen)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203d2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
